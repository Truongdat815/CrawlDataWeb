import time
import os
from src.webnovel_scraper import WebnovelScraper

def get_links_test():
    print("üîó WEBNOVEL LINK COLLECTOR (CH·∫æ ƒê·ªò TEST - L·∫§Y √çT LINK)")
    print("-" * 60)
    
    # M·∫∑c ƒë·ªãnh l·∫•y 5 b·ªô ƒë·ªÉ b·∫°n c√≥ d∆∞ l·ª±a ch·ªçn cho b√†i test 3 b·ªô
    TARGET_BOOKS = 5 
    
    url = input("Nh·∫≠p Link Category (V√≠ d·ª•: https://www.webnovel.com/stories/fanfic): ").strip()
    if not url: return

    # D√πng Chrome th·∫≠t ƒë·ªÉ tr√°nh b·ªã ch·∫∑n khi cu·ªôn
    scraper = WebnovelScraper(headless=False, block_resources=False)
    scraper.start()
    
    try:
        print(f"\nüåê ƒêang v√†o trang: {url}")
        scraper.page.goto(url, timeout=60000, wait_until='domcontentloaded')
        time.sleep(5) # ƒê·ª£i load ban ƒë·∫ßu

        # Click ƒë·ªÉ focus
        try: scraper.page.mouse.click(500, 500)
        except: pass

        book_links = set()
        
        print(f"\nüìú ƒêang l·∫•y link (M·ª•c ti√™u: {TARGET_BOOKS} truy·ªán)...")
        
        # Cu·ªôn v√†i l·∫ßn l√† ƒë·ªß
        for i in range(3):
            # L·∫•y link hi·ªán t·∫°i
            elements = scraper.page.locator("a[href*='/book/']").all()
            for el in elements:
                try:
                    href = el.get_attribute("href")
                    if href and "/book/" in href:
                        if href.startswith("/"): href = "https://www.webnovel.com" + href
                        if "?" in href: href = href.split("?")[0]
                        if "webnovel.com/book/" in href:
                            book_links.add(href)
                except: pass
            
            print(f"   ƒê√£ t√¨m th·∫•y: {len(book_links)} truy·ªán.")
            
            if len(book_links) >= TARGET_BOOKS:
                break
                
            # Cu·ªôn xu·ªëng
            scraper.page.keyboard.press("PageDown")
            time.sleep(1)
            scraper.page.keyboard.press("PageDown")
            time.sleep(2)

        # L∆∞u file
        if book_links:
            # L·∫•y ƒë√∫ng s·ªë l∆∞·ª£ng c·∫ßn thi·∫øt
            final_links = list(book_links)[:TARGET_BOOKS]
            
            with open("books_queue.txt", "w", encoding="utf-8") as f:
                for link in final_links:
                    f.write(link + "\n")
            
            print(f"\n‚úÖ ƒê√£ l∆∞u {len(final_links)} link v√†o 'books_queue.txt'.")
            print("üëâ S·∫µn s√†ng cho b√†i test ch·∫°y Batch Runner!")
        else:
            print("‚ùå Kh√¥ng t√¨m th·∫•y link n√†o.")

    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
    finally:
        if scraper.browser: scraper.browser.close()
        if scraper.playwright: scraper.playwright.stop()

if __name__ == "__main__":
    get_links_test()