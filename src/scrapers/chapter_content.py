"""
Chapter Content scraper module - handles chapter text content for Wattpad.
Responsible for: chapter body text, HTML content, etc.
"""

import hashlib
from src.scrapers.base import BaseScraper, safe_print
from src import config
from src.utils.validation import validate_against_schema
from src.schemas.chapter_content_schema import CHAPTER_CONTENT_SCHEMA


class ChapterContentScraper(BaseScraper):
    """Scraper for chapter content/body (Wattpad schema)"""
    
    # CSS selectors for extracting content - Updated based on actual Wattpad HTML structure
    CONTENT_CONTAINER_SELECTOR = 'div.panel-reading'
    PARAGRAPH_SELECTOR = 'div.panel-reading p'
    
    def __init__(self, page=None, mongo_db=None):
        super().__init__(page, mongo_db, config)
        self.init_collections({"chapter_contents": "chapter_contents"})
    
    @staticmethod
    def map_html_to_chapter_content(chapter_text, chapter_id):
        """
        Map chapter text content to Wattpad chapter content schema with validation
        
        Args:
            chapter_text: Chapter text content (t·ª´ Playwright extraction)
            chapter_id: Parent chapter ID
        
        Returns:
            dict formatted theo Wattpad chapter content schema, or None if invalid
        """
        try:
            # Generate contentId t·ª´ chapterId
            content_id = f"{chapter_id}_content"
            
            mapped = {
                "contentId": content_id,
                "chapterId": str(chapter_id),
                "content": chapter_text or "",
            }
            
            # ‚úÖ Validate before return
            validated = validate_against_schema(mapped, CHAPTER_CONTENT_SCHEMA, strict=False)
            return validated
        except Exception as e:
            safe_print(f"‚ö†Ô∏è  Chapter content validation failed: {e}")
            return None
    
    async def extract_chapter_content_from_page(self, page, chapter_id):
        """
        Tr√≠ch xu·∫•t n·ªôi dung chapter t·ª´ Playwright page
        
        Args:
            page: Playwright page object (ƒë√£ load chapter)
            chapter_id: Chapter ID (parent)
        
        Returns:
            dict ch·ª©a chapter content data (mapped + validated)
        """
        try:
            if not page:
                safe_print(f"‚ö†Ô∏è  No page object provided")
                return None
            
            full_content = ""
            
            # 1. Ch·ªù kh·ªëi n·ªôi dung t·∫£i xong
            # CSS selector: div.panel-reading (content container d·ª±a tr√™n HTML th·ª±c t·∫ø)
            try:
                await page.wait_for_selector(self.CONTENT_CONTAINER_SELECTOR, timeout=30000)
                safe_print(f"   ‚úÖ Content container loaded (div.panel-reading)")
            except Exception as e:
                safe_print(f"   ‚ö†Ô∏è  Content container not found: {e}")
                return None
            
            # 2. L·∫•y T·∫§T C·∫¢ c√°c ƒëo·∫°n vƒÉn (paragraphs) t·ª´ b√™n trong container
            # Extract paragraph text ch·ªâ t·ª´ <p> tags, b·ªè qua nested elements (buttons, divs)
            try:
                # S·ª≠ d·ª•ng Playwright ƒë·ªÉ l·∫•y text t·ª´ m·ªói <p> tag ri√™ng bi·ªát
                # ƒêi·ªÅu n√†y ƒë·∫£m b·∫£o ch√∫ng ta ch·ªâ l·∫•y text tr·ª±c ti·∫øp, kh√¥ng l·∫•y text t·ª´ buttons/divs
                p_locators = await page.locator(self.PARAGRAPH_SELECTOR).all()
                paragraphs = []
                
                for p_locator in p_locators:
                    # L·∫•y text content t·ª´ <p> tag
                    p_text = await p_locator.inner_text()
                    if p_text and p_text.strip():  # Ch·ªâ l·∫•y n·∫øu kh√¥ng r·ªóng
                        paragraphs.append(p_text.strip())
                
                safe_print(f"   ‚úÖ Tr√≠ch xu·∫•t {len(paragraphs)} paragraphs")
                
                # 3. N·ªëi c√°c ƒëo·∫°n l·∫°i th√†nh m·ªôt kh·ªëi vƒÉn b·∫£n duy nh·∫•t
                full_content = "\n\n".join(paragraphs)
                safe_print(f"   ‚úÖ Full content: {len(full_content)} characters")
            except Exception as e:
                safe_print(f"   ‚ö†Ô∏è  L·ªói khi l·∫•y paragraphs: {e}")
                return None
            
            # Map v√† validate
            processed_content = self.map_html_to_chapter_content(full_content, chapter_id)
            if processed_content:
                safe_print(f"‚úÖ Tr√≠ch xu·∫•t chapter content th√†nh c√¥ng: {len(full_content)} bytes")
            
            return processed_content
        except Exception as e:
            safe_print(f"‚ö†Ô∏è  L·ªói khi tr√≠ch xu·∫•t chapter content: {e}")
            return None
    
    @staticmethod
    def extract_text_from_html(page_html):
        """
        Tr√≠ch xu·∫•t text content t·ª´ HTML page (parsing)
        
        Args:
            page_html: HTML content string
        
        Returns:
            Extracted text content
        """
        try:
            from bs4 import BeautifulSoup
            import re
            
            soup = BeautifulSoup(page_html, 'html.parser')
            
            # T√¨m content container
            # Th·ª≠ nhi·ªÅu selectors kh√°c nhau
            content_div = None
            
            # 1. Try div.panel-reading (older version)
            content_div = soup.find('div', class_='panel-reading')
            
            # 2. Try article tag (newer version)
            if not content_div:
                content_div = soup.find('article')
            
            # 3. Try div v·ªõi class ch·ª©a 'content'
            if not content_div:
                content_divs = soup.find_all('div')
                for div in content_divs:
                    classes = div.get('class') or []
                    if classes:
                        for cls in classes:
                            if isinstance(cls, str) and 'content' in cls.lower():
                                content_div = div
                                break
                    if content_div:
                        break
            
            if not content_div:
                safe_print(f"‚ö†Ô∏è  Kh√¥ng t√¨m ƒë∆∞·ª£c content container")
                return ""
            
            # Extract paragraphs t·ª´ container
            paragraphs = []
            for p in content_div.find_all('p'):
                # L·∫•y text t·ª´ <p> tag, b·ªè qua nested elements (buttons, spans)
                p_text = p.get_text(strip=True)
                if p_text and len(p_text.strip()) > 0:
                    paragraphs.append(p_text)
            
            # Join paragraphs
            full_text = "\n\n".join(paragraphs)
            return full_text
        except Exception as e:
            safe_print(f"‚ö†Ô∏è  L·ªói khi parse HTML: {e}")
            return ""
    
    @staticmethod
    def extract_text_from_html_with_parse(page_html):
        """
        Tr√≠ch xu·∫•t chapter content t·ª´ HTML page (parse + convert to text)
        
        Args:
            page_html: HTML content c·ªßa chapter page
        
        Returns:
            Extracted chapter text
        """
        try:
            if not page_html:
                return ""
            
            text_content = ChapterContentScraper.extract_text_from_html(page_html)
            return text_content
        except Exception as e:
            safe_print(f"‚ö†Ô∏è  L·ªói khi extract text t·ª´ HTML: {e}")
            return ""
    
    @staticmethod
    def extract_and_map_chapter_content(page_html, chapter_id):
        """
        Extract chapter content t·ª´ HTML page v√† map v√†o schema
        
        Args:
            page_html: HTML content c·ªßa chapter page
            chapter_id: Chapter ID
        
        Returns:
            dict ch·ª©a chapter content data (mapped + validated) ho·∫∑c None
        """
        try:
            # Extract text t·ª´ HTML
            chapter_text = ChapterContentScraper.extract_text_from_html_with_parse(page_html)
            
            if not chapter_text:
                safe_print(f"‚ö†Ô∏è  Kh√¥ng extract ƒë∆∞·ª£c text t·ª´ HTML")
                return None
            
            # Map v√†o schema
            processed_content = ChapterContentScraper.map_html_to_chapter_content(chapter_text, chapter_id)
            return processed_content
        except Exception as e:
            safe_print(f"‚ö†Ô∏è  L·ªói khi extract chapter content: {e}")
            return None
    
    def extract_chapter_content_from_html(self, page_html, chapter_id):
        """
        Tr√≠ch xu·∫•t n·ªôi dung chapter t·ª´ HTML string (fallback if async not available)
        
        Args:
            page_html: HTML content c·ªßa chapter page
            chapter_id: Chapter ID (parent)
        
        Returns:
            dict ch·ª©a chapter content data (mapped + validated)
        """
        try:
            if not page_html:
                safe_print(f"‚ö†Ô∏è  No HTML content to extract")
                return None
            
            # Map v√† validate
            processed_content = self.map_html_to_chapter_content(page_html, chapter_id)
            if processed_content:
                safe_print(f"‚úÖ Tr√≠ch xu·∫•t chapter content t·ª´ HTML: {len(page_html)} bytes")
            
            return processed_content
        except Exception as e:
            safe_print(f"‚ö†Ô∏è  L·ªói khi tr√≠ch xu·∫•t chapter content: {e}")
            return None
    
    def save_chapter_content_to_mongo(self, content_data):
        """
        L∆∞u chapter content v√†o MongoDB
        
        Args:
            content_data: dict ch·ª©a th√¥ng tin chapter content (Wattpad schema)
        """
        if not content_data or not self.collection_exists("chapter_contents"):
            return
        
        try:
            collection = self.get_collection("chapter_contents")
            if collection is None:
                return
            
            existing = collection.find_one({"contentId": content_data.get("contentId")})
            
            if existing:
                # Update n·∫øu content ƒë√£ t·ªìn t·∫°i
                collection.update_one(
                    {"contentId": content_data.get("contentId")},
                    {"$set": content_data}
                )
                safe_print(f"  üìù C·∫≠p nh·∫≠t chapter content: {content_data.get('contentId')}")
            else:
                collection.insert_one(content_data)
                safe_print(f"  ‚ú® Th√™m m·ªõi chapter content: {content_data.get('contentId')}")
        except Exception as e:
            safe_print(f"        ‚ö†Ô∏è  L·ªói khi l∆∞u chapter content v√†o MongoDB: {e}")
